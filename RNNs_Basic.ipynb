{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) One-to-Many:\n",
    "        Image Captioning:\n",
    "            One  : Image as is, OR\n",
    "                   Image coded by CNN, then fed to RNN as a vector.\n",
    "            Many : Let RNN output captions by rolling out indefinitely. \n",
    "\n",
    "    2) Many-to-One:\n",
    "        Sentiment Analysis:\n",
    "            Many : The text words embedded into many vectors, ordered.\n",
    "            One  : Output is the sentiment.\n",
    "                Method 1: Sum/Concat of all unrolled-RNN output to classifiation layer.\n",
    "                Method 2:             Use only final RNN output to classifiation layer.\n",
    "\n",
    "    3) Many-to-Many:\n",
    "        Version 1: Finish reading the sequence first. Then use final RNN-state to output/start another sequence.\n",
    "            Sequence Prediction:\n",
    "                Many(Input)  : [0,1,2,3]\n",
    "                Many(Output) :          [4,5,6,7]\n",
    "            Machine Translation:\n",
    "                Many(Input)  : ['I','want']\n",
    "                Many(Output) :             ['我','要']\n",
    "\n",
    "        Version 2: For each input to the RNN, there will be output.\n",
    "            Memorizing hello:\n",
    "                Many(Input)  : ['h','e','l','l']\n",
    "                Many(Output) :     ['e','l','l','o']\n",
    "            Sequence Labelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "## To get helper functions from ano`ther folder\n",
    "# sys.path.insert(0, '../') # if _helper_basics_ is in previous folder\n",
    "now_i_am_at = 'home' # home dso test\n",
    "if now_i_am_at=='home':\n",
    "    sys.path.insert(0, 'E:/Leonard HDD/Dropbox/DSO/Tasks/')\n",
    "elif now_i_am_at=='dso':\n",
    "    sys.path.insert(0, 'D:/Dropbox/DSO/Tasks')\n",
    "\n",
    "from _helper_basics_ import *\n",
    "\n",
    "## Deep learning\n",
    "import tensorflow as tf\n",
    "# import keras\n",
    "# from keras.models import Model, Sequential\n",
    "# from keras.layers import *\n",
    "# from keras import optimizers\n",
    "# import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras 2.0.5\n",
      "tensorflow 1.2.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "## Why need autoreload - https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print('keras', keras.__version__)\n",
    "print('tensorflow', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-to-Many LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image/Video Captioning\n",
    "    1) Image is input:\n",
    "            (Input)  : [frame_1]\n",
    "            (Encode) : [ Code  ]->[Code][Code][Code]\n",
    "            (Output) :            [  I,  eat,  rice]\n",
    "    2) Video is input: \n",
    "            (Input)  : [frame_1,...,frame_N]\n",
    "            (Encode) : [        Code       ]->[Code][Code][Code]\n",
    "            (Output) :                        [  I,  eat,  rice]\n",
    "    3) Code is input:\n",
    "            (Input)  : [        Code       ]->[Code][Code][Code]\n",
    "            (Output) :                        [  I,  eat,  rice]\n",
    "        \n",
    "P.S for 2) we can alternatively read them sequentially (scroll to many-to-many)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_X(Input_type, Input_Dimensions):\n",
    "    m,n,channel,num_code,num_frames,num_words,num_feat_out = Input_Dimensions\n",
    "    if Input_type == 'image':\n",
    "        X = np.random.rand(1, m,n, channel)\n",
    "    if Input_type == 'video':\n",
    "        X = np.random.rand(1, num_frames, m,n, channel)\n",
    "    elif Input_type == 'embedding':\n",
    "        X = np.random.rand(1, num_code)\n",
    "    return X\n",
    "def set_Archi(Input_type, Input_Dimensions):\n",
    "    m,n,channel,num_code,num_frames,num_words,num_feat_out = Input_Dimensions\n",
    "    if Input_type == 'image':\n",
    "        Inp = Input( shape=(m,n,channel),name = \"Image\" )\n",
    "        ####################### Generate Image_Code (ConvNet) #######################\n",
    "        x = Conv2D(64, (3,3), name='Conv2D')(Inp) # padding='same'\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(num_code, name='Image_Code')(x)\n",
    "    if Input_type == 'video':\n",
    "        Inp = Input( shape=(num_frames, m,n,channel),name = \"Image\" )\n",
    "        ####################### Generate Video_Code (ConvNet) #######################\n",
    "        x = Conv3D(64, (5,3,3), name='Conv3D')(Inp) # padding='same'\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(num_code, name='Video_Code')(x)\n",
    "    elif Input_type == 'embedding':\n",
    "        ########################### Input already a code ############################\n",
    "        Inp = Input( shape=(num_code,), name = \"Image_Code\" )\n",
    "        x = Inp\n",
    "    return Inp, x\n",
    "\n",
    "Input_type = 'video'  # 'image' 'video' 'embedding'\n",
    "\n",
    "m,n,channel  = 5,5,3\n",
    "num_code     = 64 # Image/Video Code\n",
    "num_frames   = 99 # Video Frames\n",
    "num_words    = 10\n",
    "num_feat_out = 2\n",
    "\n",
    "## Input : \n",
    "Input_Dimensions = [m,n,channel,num_code,num_frames,num_words,num_feat_out]\n",
    "X = set_X(Input_type, Input_Dimensions)\n",
    "\n",
    "## Output : (None, num_words, num_feat_out)\n",
    "y = np.random.rand(1, num_words, num_feat_out)\n",
    "\n",
    "########################### Architecture ##################################\n",
    "Inp, x = set_Archi(Input_type, Input_Dimensions)\n",
    "########## Recurrent Section ##########\n",
    "x = RepeatVector(num_words, name='Repeat')(x)  ## To tally with num_words\n",
    "x = LSTM(num_feat_out, name=\"RNN_1\", return_sequences=True)(x)\n",
    "########################### Printing information ########################\n",
    "model = Model(Inp, x)\n",
    "model.summary()\n",
    "# print_model_weights(model)\n",
    "################################# Training ##############################\n",
    "n_batch = 1\n",
    "n_epoch = 1\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=1)\n",
    "############################### Evaluation #############################\n",
    "result = model.predict(X)\n",
    "# print('X:\\n',X[0].T)\n",
    "# print('result:\\n',result[0].T)\n",
    "# print('y:\\n',y[0].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-One LSTM for Sequence Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 5, 1)              0         \n",
      "_________________________________________________________________\n",
      "RNN_1 (LSTM)                 (None, 99)                39996     \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 2)                 200       \n",
      "=================================================================\n",
      "Total params: 40,196\n",
      "Trainable params: 40,196\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "X:\n",
      " [[ 0.   0.2  0.4  0.6  0.8]]\n",
      "result:\n",
      " [  2.79839151e-06   9.99999881e-01]\n",
      "y:\n",
      " [0 1]\n"
     ]
    }
   ],
   "source": [
    "num_words  = 5\n",
    "num_feat   = 1\n",
    "num_class  = 2\n",
    "class_type = np.array([0,1])\n",
    "\n",
    "## Input : (None, num_words, num_feat)\n",
    "seq = np.array( [i/float(num_words) for i in range(num_words)] )\n",
    "X = seq.reshape(1, num_words, num_feat)\n",
    "\n",
    "## Output : (None, num_class)\n",
    "y = class_type.reshape(1, num_class)\n",
    "\n",
    "########################### Architecture ##################################\n",
    "Inp = Input(shape=(num_words,num_feat), name=\"Input\")\n",
    "x   = LSTM(99, name=\"RNN_1\")(Inp) \n",
    "x   = Dense(num_class,name = \"Output\" )(x)\n",
    "model = Model(Inp, x)\n",
    "########################### Printing information ########################\n",
    "model.summary()\n",
    "# print_model_weights(model)\n",
    "############################### Evaluation #############################\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=0)\n",
    "############################### Evaluation #############################\n",
    "result = model.predict(X, batch_size=1, verbose=0)\n",
    "print('X:\\n',X[0].T)\n",
    "print('result:\\n',result[0].T)\n",
    "print('y:\\n',y[0].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Many-to-Many RNNs\n",
    "    There are two versions. \n",
    "    1) First is to read all sequence then store it in a memory cell. Subsequently, output from either the memory state, or output->input.\n",
    "    2) Second is to have output directly from the inputs, instead of reading all the sequences first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1)\n",
    "### Same Input Output Length\n",
    "    Speech Enhancement, Sequence Prediction,\n",
    "        (Input)  : [0,1,2,3]->State\n",
    "        (Output) :            State->[4,5,6,7]\n",
    "### Diff Input Output Length\n",
    "    Machine Translation, Video Captioning\n",
    "        (Input)  : [I,want,to,eat]->State\n",
    "        (Output) :                  State->[我,要,吃]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 4, 1)              0         \n",
      "_________________________________________________________________\n",
      "Encoder (LSTM)               (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "Repeat (RepeatVector)        (None, 3, 10)             0         \n",
      "_________________________________________________________________\n",
      "Decoder_1 (LSTM)             (None, 3, 10)             840       \n",
      "_________________________________________________________________\n",
      "Decoder_2 (LSTM)             (None, 3, 1)              48        \n",
      "=================================================================\n",
      "Total params: 1,368\n",
      "Trainable params: 1,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "X:\n",
      " [0 1 2 3]\n",
      "predict:\n",
      " [ 3.9658339   4.99893379  6.02482462]\n",
      "y:\n",
      " [4 5 6]\n"
     ]
    }
   ],
   "source": [
    "num_features  = 1\n",
    "num_words_in  = 4\n",
    "LSTM_neurons  = 10\n",
    "num_words_out = 3\n",
    "## Input : (None, num_words_in, num_features)\n",
    "X = np.array([0,1,2,3]).reshape(1,num_words_in, num_features)\n",
    "## Output : (None, num_words, num_feat_out)\n",
    "y = np.array([4,5,6]).reshape(1,num_words_out,num_features)\n",
    "########################### Architecture ##################################\n",
    "Inp = Input( shape=(num_words_in, num_features),name = \"Input\" )\n",
    "x = LSTM(LSTM_neurons, name = \"Encoder\")(Inp)\n",
    "x = RepeatVector(num_words_out, name='Repeat')(x)\n",
    "x = LSTM(LSTM_neurons, name = \"Decoder_1\", return_sequences=True)(x)\n",
    "x = LSTM(num_features, activation='relu', name = \"Decoder_2\", return_sequences=True)(x)\n",
    "########################### Printing information ########################\n",
    "model = Model(inputs=Inp, outputs=x)\n",
    "model.summary()\n",
    "# print_model_weights(model)\n",
    "########################### Training ########################\n",
    "n_batch = 1\n",
    "n_epoch = 1000\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=0)\n",
    "########################### Evaluations ########################\n",
    "print('X:\\n',X.reshape(num_words_in))\n",
    "print('predict:\\n', model.predict(X.reshape(1,num_words_in,num_features)).reshape(num_words_out).T)\n",
    "print('y:\\n',y.reshape(num_words_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2)\n",
    "### Teacher Forcing ?\n",
    "    Many(Input)  : [<start>, h, e, l, l,   o   ]\n",
    "    Many(Output) : [   h,    e, l, l, o, <stop>]\n",
    "    \n",
    "    Many(Input)  : [<start>, I, want, to,   eat,   rice   ]\n",
    "    Many(Output) : [   I,  want, to,  eat, rice,    .  ]\n",
    "Edit : include embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 6, 3)              0         \n",
      "_________________________________________________________________\n",
      "RNN_1 (LSTM)                 (None, 6, 10)             560       \n",
      "_________________________________________________________________\n",
      "Output (LSTM)                (None, 6, 3)              168       \n",
      "=================================================================\n",
      "Total params: 728\n",
      "Trainable params: 728\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "X:\n",
      " [[ 1.  1.  0.  1.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  1.  1.  1.]]\n",
      "result:\n",
      " [[ 0.6140694   0.14179491  0.91301763  0.9592908   0.03574775  0.        ]\n",
      " [ 0.62702775  0.10392392  0.          0.01219696  0.96042001  0.98396033]\n",
      " [ 0.26099342  0.82136625  0.92331982  0.9699052   0.9684999   0.0079239 ]]\n",
      "predict:\n",
      " [[ 1.  0.  1.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  1.  1.]\n",
      " [ 0.  1.  1.  1.  1.  0.]]\n",
      "y:\n",
      " [[ 1.  0.  1.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  1.  1.]\n",
      " [ 0.  1.  1.  1.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "vocab = 1.*np.array([[1,0,0],  # <start>\n",
    "                     [0,1,0],  # <stop>\n",
    "                     [1,1,0],  # h\n",
    "                     [0,0,1],  # e\n",
    "                     [1,0,1],  # l\n",
    "                     [0,1,1]]) # o\n",
    "# print(vocab.T, vocab.shape)\n",
    "vocab_size   = np.shape(vocab)[0]\n",
    "num_words    = 6\n",
    "num_features = np.shape(vocab)[1]\n",
    "hello    = vocab[2:]\n",
    "## Input : (None, num_words, num_features)\n",
    "X = np.array([ vocab[0],hello[0],hello[1],hello[2],hello[2],hello[3] ])\n",
    "X = X.reshape(1,num_words,num_features)\n",
    "## Output : (None, num_words, num_features)\n",
    "y = np.array([ hello[0],hello[1],hello[2],hello[2],hello[3],vocab[1] ])\n",
    "y = y.reshape(1,num_words,num_features)\n",
    "########################### Architecture ##################################\n",
    "Inp = Input( shape=( num_words,num_features),name = \"Input\" )\n",
    "x = LSTM(10, name = \"RNN_1\", return_sequences=True)(Inp) \n",
    "x = LSTM(num_features, activation='sigmoid', name = \"Output\", return_sequences=True)(x) \n",
    "########################### Printing information ########################\n",
    "model = Model(Inp, x)\n",
    "model.summary()\n",
    "# print_model_weights(model)\n",
    "################################# Training ##############################\n",
    "n_batch = 1\n",
    "n_epoch = 500\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=0)\n",
    "################################ Evaluation #############################\n",
    "result = model.predict(X)\n",
    "print('X:\\n',X[0].T)\n",
    "print('result:\\n',result[0].T)\n",
    "print('predict:\\n',np.round(result[0].T))\n",
    "print('y:\\n',y[0].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Captioning\n",
    "### Using Functional Model with TimeDistributed wrapper\n",
    "    Many(Input)  : ['frame_1','frame_2','frame_3','frame_4']\n",
    "    Encode_Layer : [ 'code_1', 'code_2', 'code_3', 'code_4']\n",
    "    Many(Output) :                                  ['I','eat','rice','.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Video (InputLayer)           (None, 99, 10, 10, 3)     0         \n",
      "_________________________________________________________________\n",
      "Conv2D (TimeDistributed)     (None, 99, 8, 8, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Flatten (TimeDistributed)    (None, 99, 4096)          0         \n",
      "_________________________________________________________________\n",
      "Code_Seq (TimeDistributed)   (None, 99, 64)            262208    \n",
      "_________________________________________________________________\n",
      "Encoder (LSTM)               (None, 2)                 536       \n",
      "_________________________________________________________________\n",
      "Repeat (RepeatVector)        (None, 15, 2)             0         \n",
      "_________________________________________________________________\n",
      "Decoder (LSTM)               (None, 15, 2)             40        \n",
      "=================================================================\n",
      "Total params: 264,576\n",
      "Trainable params: 264,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Number of layers: (7,)\n",
      "Number of trainable parameters :\n",
      "  1) Input : 0\n",
      "  2) Hidden : 2\n",
      "     Weight 1: (3, 3, 3, 64) \n",
      "     Weight 2: (64,) \n",
      "  3) Hidden : 0\n",
      "  4) Hidden : 2\n",
      "     Weight 1: (4096, 64) \n",
      "     Weight 2: (64,) \n",
      "  5) Hidden : 3\n",
      "     Weight 1: (64, 8) \n",
      "     Weight 2: (2, 8) \n",
      "     Weight 3: (8,) \n",
      "  6) Hidden : 0\n",
      "  7) Output : 3\n",
      "     Weight 1: (2, 8) \n",
      "     Weight 2: (2, 8) \n",
      "     Weight 3: (8,) \n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s - loss: 0.2343\n",
      "result:\n",
      " [[ 0.13962644  0.21238795  0.24941117  0.26844218  0.27818111  0.28303084\n",
      "   0.28531462  0.28628275  0.28660631  0.28663802  0.28655624  0.28644574\n",
      "   0.28634268  0.28625932  0.28619692]\n",
      " [-0.00141921  0.01745235  0.03885317  0.05688616  0.07046529  0.08010356\n",
      "   0.08668993  0.09106573  0.09390613  0.09571241  0.09683926  0.09752937\n",
      "   0.09794421  0.09818885  0.09833016]]\n",
      "y:\n",
      " [[ 0.32535673  0.69189948  0.88311978  0.87639658  0.0805953   0.87063238\n",
      "   0.26879113  0.099228    0.15657812  0.41270295  0.02730444  0.22418752\n",
      "   0.88245872  0.98679262  0.23184019]\n",
      " [ 0.21441654  0.63295813  0.04094162  0.34919152  0.80066882  0.07360684\n",
      "   0.04132478  0.73851869  0.11605575  0.09945894  0.84509869  0.29432824\n",
      "   0.97363066  0.2388308   0.46074053]]\n"
     ]
    }
   ],
   "source": [
    "Input_type = 'video' # 'embedding' 'video'\n",
    "\n",
    "num_frames, m,n,channel = 99, 10,10, 3\n",
    "num_code = 64\n",
    "num_words, num_feat_out = 15, 2\n",
    "\n",
    "## Input : \n",
    "if Input_type == 'video':       X = np.random.rand(1, num_frames, m,n, channel)\n",
    "elif Input_type == 'embedding': X = np.random.rand(1, num_frames, num_code)\n",
    "\n",
    "## Output : (None, num_words, num_feat_out)\n",
    "y = np.random.rand(1, num_words, num_feat_out)\n",
    "\n",
    "########################### Architecture ##################################\n",
    "if Input_type == 'video':\n",
    "    ## Input\n",
    "    Inp_vid = Input(shape=(num_frames, m,n, channel), name=\"Video\")\n",
    "    ## Coded frames\n",
    "    x = TimeDistributed(Conv2D(64, (3,3)),name=\"Conv2D\")(Inp_vid)\n",
    "    x = TimeDistributed(Flatten(),name=\"Flatten\")(x)\n",
    "    x = TimeDistributed(Dense(num_code), name=\"Code_Seq\")(x)\n",
    "    ## Encoder\n",
    "    x = LSTM(num_feat_out, name=\"Encoder\")(x)  \n",
    "    x = RepeatVector( num_words, name='Repeat')(x)\n",
    "    ## Decoder\n",
    "    x = LSTM(num_feat_out, return_sequences=True, name=\"Decoder\")(x)  \n",
    "    model = Model(inputs=Inp_vid, outputs=x)\n",
    "\n",
    "elif Input_type == 'embedding':\n",
    "    Inp = Input( shape=(num_frames,num_code), name=\"Input\" )\n",
    "    ## Encoder\n",
    "    x = LSTM(num_feat_out, name=\"Encoder\")(Inp) \n",
    "    x = RepeatVector( num_words,   name='Repeat')(x)\n",
    "    ## Decoder\n",
    "    x = LSTM(num_feat_out, return_sequences=True, name=\"Decoder\")(x)  \n",
    "    model = Model(Inp, x)\n",
    "########################### Printing information ########################\n",
    "model.summary()\n",
    "print_model_weights(model)\n",
    "\n",
    "################################# Training ##############################\n",
    "n_batch = 1\n",
    "n_epoch = 1\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(X, y, epochs=n_epoch, batch_size=n_batch, verbose=1)\n",
    "############################### Evaluation #############################\n",
    "result = model.predict(X)\n",
    "# print('X:\\n',X[0].T)\n",
    "print('result:\\n',result[0].T)\n",
    "print('y:\\n',y[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', \n",
    "     recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, \n",
    "     recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, \n",
    "     recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Vid_Frame (InputLayer)       (None, 10, 2)             0         \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 10, 3)             72        \n",
      "=================================================================\n",
      "Total params: 72\n",
      "Trainable params: 72\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Inp = Input( shape=(10,2), name=\"Vid_Frame\" )\n",
    "x = LSTM(3, return_sequences=True)(Inp)\n",
    "#     x = Dense(64, name='Vid_Frame_Code')(x)\n",
    "model = Model(Inp ,x)\n",
    "########################### Printing information ########################\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.random.rand(2,10,2)\n",
    "results = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 3)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset_file(dataset, default_dataset, origin):\n",
    "    '''Look for it as if it was a full path, if not, try local file,\n",
    "    if not try in the data directory.\n",
    "\n",
    "    Download dataset if it is not present\n",
    "\n",
    "    '''\n",
    "    data_dir, data_file = os.path.split(dataset)\n",
    "    if data_dir == \"\" and not os.path.isfile(dataset):\n",
    "        # Check if dataset is in the data directory.\n",
    "        new_path = os.path.join(\n",
    "            os.path.split(__file__)[0],\n",
    "            \"..\",\n",
    "            \"data\",\n",
    "            dataset\n",
    "        )\n",
    "        if os.path.isfile(new_path) or data_file == default_dataset:\n",
    "            dataset = new_path\n",
    "\n",
    "    if (not os.path.isfile(dataset)) and data_file == default_dataset:\n",
    "        from six.moves import urllib\n",
    "        print('Downloading data from %s' % origin)\n",
    "        urllib.request.urlretrieve(origin, dataset)\n",
    "\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_data(path=\"imdb.pkl\", n_words=100000, valid_portion=0.1, maxlen=None,\n",
    "              sort_by_len=True):\n",
    "    '''Loads the dataset\n",
    "\n",
    "    :type path: String\n",
    "    :param path: The path to the dataset (here IMDB)\n",
    "    :type n_words: int\n",
    "    :param n_words: The number of word to keep in the vocabulary.\n",
    "        All extra words are set to unknow (1).\n",
    "    :type valid_portion: float\n",
    "    :param valid_portion: The proportion of the full train set used for\n",
    "        the validation set.\n",
    "    :type maxlen: None or positive int\n",
    "    :param maxlen: the max sequence length we use in the train/valid set.\n",
    "    :type sort_by_len: bool\n",
    "    :name sort_by_len: Sort by the sequence lenght for the train,\n",
    "        valid and test set. This allow faster execution as it cause\n",
    "        less padding per minibatch. Another mechanism must be used to\n",
    "        shuffle the train set at each epoch.\n",
    "\n",
    "    '''\n",
    "\n",
    "    #############\n",
    "    # LOAD DATA #\n",
    "    #############\n",
    "\n",
    "    # Load the dataset\n",
    "    path = get_dataset_file(\n",
    "        path, \"imdb.pkl\",\n",
    "        \"http://www.iro.umontreal.ca/~lisa/deep/data/imdb.pkl\")\n",
    "\n",
    "    if path.endswith(\".gz\"):\n",
    "        f = gzip.open(path, 'rb')\n",
    "    else:\n",
    "        f = open(path, 'rb')\n",
    "\n",
    "    train_set = pickle.load(f)\n",
    "    test_set = pickle.load(f)\n",
    "    f.close()\n",
    "    if maxlen:\n",
    "        new_train_set_x = []\n",
    "        new_train_set_y = []\n",
    "        for x, y in zip(train_set[0], train_set[1]):\n",
    "            if len(x) < maxlen:\n",
    "                new_train_set_x.append(x)\n",
    "                new_train_set_y.append(y)\n",
    "        train_set = (new_train_set_x, new_train_set_y)\n",
    "        del new_train_set_x, new_train_set_y\n",
    "\n",
    "    # split training set into validation set\n",
    "    train_set_x, train_set_y = train_set\n",
    "    n_samples = len(train_set_x)\n",
    "    sidx = numpy.random.permutation(n_samples)\n",
    "    n_train = int(numpy.round(n_samples * (1. - valid_portion)))\n",
    "    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]\n",
    "    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]\n",
    "    train_set_x = [train_set_x[s] for s in sidx[:n_train]]\n",
    "    train_set_y = [train_set_y[s] for s in sidx[:n_train]]\n",
    "\n",
    "    train_set = (train_set_x, train_set_y)\n",
    "    valid_set = (valid_set_x, valid_set_y)\n",
    "\n",
    "    def remove_unk(x):\n",
    "        return [[1 if w >= n_words else w for w in sen] for sen in x]\n",
    "\n",
    "    test_set_x, test_set_y = test_set\n",
    "    valid_set_x, valid_set_y = valid_set\n",
    "    train_set_x, train_set_y = train_set\n",
    "\n",
    "    train_set_x = remove_unk(train_set_x)\n",
    "    valid_set_x = remove_unk(valid_set_x)\n",
    "    test_set_x = remove_unk(test_set_x)\n",
    "\n",
    "    def len_argsort(seq):\n",
    "        return sorted(range(len(seq)), key=lambda x: len(seq[x]))\n",
    "\n",
    "    if sort_by_len:\n",
    "        sorted_index = len_argsort(test_set_x)\n",
    "        test_set_x = [test_set_x[i] for i in sorted_index]\n",
    "        test_set_y = [test_set_y[i] for i in sorted_index]\n",
    "\n",
    "        sorted_index = len_argsort(valid_set_x)\n",
    "        valid_set_x = [valid_set_x[i] for i in sorted_index]\n",
    "        valid_set_y = [valid_set_y[i] for i in sorted_index]\n",
    "\n",
    "        sorted_index = len_argsort(train_set_x)\n",
    "        train_set_x = [train_set_x[i] for i in sorted_index]\n",
    "        train_set_y = [train_set_y[i] for i in sorted_index]\n",
    "\n",
    "    train = (train_set_x, train_set_y)\n",
    "    valid = (valid_set_x, valid_set_y)\n",
    "    test = (test_set_x, test_set_y)\n",
    "\n",
    "    return train, valid, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc3 in position 6: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-270-365af7f6d481>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Data/imdb.dict.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_portion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort_by_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-269-3939ece4ed2f>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(path, n_words, valid_portion, maxlen, sort_by_len)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mtrain_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc3 in position 6: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "train, valid, test = load_data(path=\"Data/imdb.dict.pkl\", n_words=100000, valid_portion=0.1, maxlen=None, sort_by_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spamreader <_csv.reader object at 0x000001B1349EB0B0>\n",
      "['Id', 'Sequence']\n",
      "['3', '1,3,13,87,1053,28576,2141733,508147108,402135275365,1073376057490373,9700385489355970183,298434346895322960005291,31479360095907908092817694945,11474377948948020660089085281068730']\n",
      "\n",
      "X_train:  (14, 1)\n",
      "['7', '1,2,1,5,5,1,11,16,7,1,23,44,30,9,1,47,112,104,48,11,1,95,272,320,200,70,13,1,191,640,912,720,340,96,15,1,383,1472,2464,2352,1400,532,126,17,1,767,3328,6400,7168,5152,2464,784,160,19,1,1535,7424']\n",
      "\n",
      "X_train:  (14, 1)\n",
      "['8', '1,2,4,5,8,10,16,20,32,40,64,80,128,160,256,320,512,640,1024,1280,2048,2560,4096,5120,8192,10240,16384,20480,32768,40960,65536,81920,131072,163840,262144,327680,524288,655360,1048576,1310720,2097152']\n",
      "\n",
      "X_train:  (14, 1)\n",
      "['11', '1,8,25,83,274,2275,132224,1060067,3312425,10997342,36304451,301432950,17519415551,140456757358,438889687625,1457125820233,4810267148324,39939263006825,2321287521544174,18610239435360217']\n",
      "\n",
      "X_train:  (14, 1)\n",
      "['13', '1,111,12211,1343211,147753211,16252853211,1787813853211,196659523853211,21632547623853211,2379580238623853211,261753826248623853211,28792920887348623853211']\n",
      "\n",
      "X_train:  (14, 1)\n",
      "['15', '1,1,1,1,1,1,1,1,1,5,1,1,1,1,5,5,1,1,1,1,11,5,5,11,5,1,1,1,1,5,23,5,23,5,5,1,1,1,1,21,5,39,5,5,39,5,21,5,1,1,1,1,5,1,17,1,17,1,1,5,1,1,1,1,31,5,5,29,1,1,29,1,5']\n",
      "\n",
      "X_train:  (14, 1)\n",
      "['16', '840,1320,1680,2520,3192,3432,4920,5208,5280,5712,6552,6888,9360,11928,16008,19152,19992,25200,29568,31080,35880,38280,38640,40920,41832,45240,47880,48360,48720,51240,51480,53040,56280,57288,61320,63240']\n",
      "\n",
      "X_train:  (14, 1)\n",
      "['18', '1,2,7,27,113,483,2138,9681,44374,205500,961614,4532177,21472917,102258257,489141279,2347573314,11300344747,54548339666,263926643851,1279497594561,6214413418672,30233348558479,147297034473933,718569377619361,3509725616656089,17161306005034007,83994842745043322']\n",
      "\n",
      "X_train:  (14, 1)\n",
      "['20', '4,6,8,9,26,1752']\n",
      "\n",
      "X_train:  (14, 1)\n"
     ]
    }
   ],
   "source": [
    "# import csv\n",
    "\n",
    "X_train = []\n",
    "\n",
    "Folder_path = \"Data/Integer_Prediction/\"\n",
    "# data_path = 'sample_submission'\n",
    "data_path = 'train'\n",
    "# data_path = 'test'\n",
    "\n",
    "with open(Folder_path+data_path+'.csv', 'r') as csvfile:\n",
    "#     spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    print('spamreader',spamreader)\n",
    "    itr = 0\n",
    "    for row in spamreader:\n",
    "        print('\\n',row)\n",
    "        itr += 1\n",
    "        if itr == 1: continue\n",
    "        \n",
    "        Id,Sequence = row\n",
    "        # print('\\tx',Id)\n",
    "        # print('\\tSequence',Sequence)\n",
    "        X = Sequence.split(\",\")\n",
    "        # print('\\tX',X)\n",
    "        for x in X:\n",
    "            X_train += [int(x)]\n",
    "\n",
    "        # print('X_train: \\n\\t',X_train)\n",
    "\n",
    "        X_train = np.array(X_train).reshape(len(X_train),1)\n",
    "        print('X_train: ',X_train.shape)\n",
    "        # print('X_train: ',X_train.T)\n",
    "        \n",
    "        if itr == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Folder_path = \"Data/Integer_Prediction/\"\n",
    "# data_path = 'sample_submission'\n",
    "data_path = 'train'\n",
    "# data_path = 'test'\n",
    "\n",
    "# load the data\n",
    "colna = ['id', 'seq']\n",
    "train = pd.read_csv(Folder_path+\"train.csv\")\n",
    "test  = pd.read_csv(Folder_path+\"test.csv\")\n",
    "\n",
    "train.columns = colna\n",
    "test.columns = colna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1,3,13,87,1053,28576,2141733,508147108,4021352...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1,2,1,5,5,1,11,16,7,1,23,44,30,9,1,47,112,104,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1,2,4,5,8,10,16,20,32,40,64,80,128,160,256,320...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1,8,25,83,274,2275,132224,1060067,3312425,1099...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1,111,12211,1343211,147753211,16252853211,1787...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                                seq\n",
       "0   3  1,3,13,87,1053,28576,2141733,508147108,4021352...\n",
       "1   7  1,2,1,5,5,1,11,16,7,1,23,44,30,9,1,47,112,104,...\n",
       "2   8  1,2,4,5,8,10,16,20,32,40,64,80,128,160,256,320...\n",
       "3  11  1,8,25,83,274,2275,132224,1060067,3312425,1099...\n",
       "4  13  1,111,12211,1343211,147753211,16252853211,1787..."
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.columns = colna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113845, 2)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              3\n",
       "1              7\n",
       "2              8\n",
       "3             11\n",
       "4             13\n",
       "5             15\n",
       "6             16\n",
       "7             18\n",
       "8             20\n",
       "9             21\n",
       "10            23\n",
       "11            24\n",
       "12            26\n",
       "13            28\n",
       "14            34\n",
       "15            35\n",
       "16            36\n",
       "17            40\n",
       "18            41\n",
       "19            44\n",
       "20            46\n",
       "21            49\n",
       "22            51\n",
       "23            52\n",
       "24            53\n",
       "25            57\n",
       "26            59\n",
       "27            61\n",
       "28            63\n",
       "29            64\n",
       "           ...  \n",
       "113815    227632\n",
       "113816    227634\n",
       "113817    227637\n",
       "113818    227638\n",
       "113819    227641\n",
       "113820    227643\n",
       "113821    227644\n",
       "113822    227645\n",
       "113823    227646\n",
       "113824    227647\n",
       "113825    227652\n",
       "113826    227656\n",
       "113827    227660\n",
       "113828    227662\n",
       "113829    227664\n",
       "113830    227666\n",
       "113831    227667\n",
       "113832    227672\n",
       "113833    227675\n",
       "113834    227676\n",
       "113835    227677\n",
       "113836    227679\n",
       "113837    227680\n",
       "113838    227681\n",
       "113839    227682\n",
       "113840    227683\n",
       "113841    227684\n",
       "113842    227686\n",
       "113843    227689\n",
       "113844    227690\n",
       "Name: id, Length: 113845, dtype: int64"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1,3,13,87,1053,28576,2141733,508147108,4021352...\n",
       "1         1,2,1,5,5,1,11,16,7,1,23,44,30,9,1,47,112,104,...\n",
       "2         1,2,4,5,8,10,16,20,32,40,64,80,128,160,256,320...\n",
       "3         1,8,25,83,274,2275,132224,1060067,3312425,1099...\n",
       "4         1,111,12211,1343211,147753211,16252853211,1787...\n",
       "5         1,1,1,1,1,1,1,1,1,5,1,1,1,1,5,5,1,1,1,1,11,5,5...\n",
       "6         840,1320,1680,2520,3192,3432,4920,5208,5280,57...\n",
       "7         1,2,7,27,113,483,2138,9681,44374,205500,961614...\n",
       "8                                           4,6,8,9,26,1752\n",
       "9         1,2,1,3,4,2,4,8,8,3,5,13,19,15,5,6,19,36,42,28...\n",
       "10        1,176,570496,9223556096,460993706622976,552660...\n",
       "11        18,24,30,36,42,54,60,66,84,108,126,138,174,186...\n",
       "12        0,0,4,7,8,4,6,8,8,9,9,5,2,1,5,3,1,1,0,0,4,7,8,...\n",
       "13        648391,718064159,7069067389,22742734291,362942...\n",
       "14        1,1,3,1,3,7,1,3,11,19,1,3,15,35,47,1,3,19,51,1...\n",
       "15        0,1,4,7,15,18,31,40,50,61,88,87,119,136,151,17...\n",
       "16        1,2,3,4,5,7,9,12,21,114,200,351,465,4410,31572...\n",
       "17                            1,3,635,2049219,7372235460687\n",
       "18        0,1,2,3,4,5,6,7,8,9,10,12,24,36,48,60,72,84,96...\n",
       "19        0,1,4,2,4,4,11,3,11,4,11,4,8,11,10,4,11,11,17,...\n",
       "20        1,2,0,-5,-5,8,21,0,-55,-55,89,233,0,-610,-610,...\n",
       "21        1,0,0,56,15,56,-1568,-840,-3248,86968,68992,28...\n",
       "22        1,3,5,7,9,11,13,5,17,19,21,23,25,27,29,31,11,7...\n",
       "23        1,2,6,3,12,15,4,20,36,28,5,30,70,80,45,6,42,12...\n",
       "24        1,1,5,15,65,231,1049,4011,18485,74073,344159,1...\n",
       "25        1,9,2,9,1,78,1,19,3,8,2,77,2,8,3,19,1,78,1,9,2...\n",
       "26        1,1,1,2,3,5,9,16,28,51,93,170,315,585,1092,204...\n",
       "27        1,8,17,100,475,2843,16691,105026,668777,437969...\n",
       "28        1,1,9,1,25,11,1,49,31,43,1,81,61,247,85,1,121,...\n",
       "29        25,52,125,152,215,512,1125,1152,1215,1251,1512...\n",
       "                                ...                        \n",
       "113815    1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,...\n",
       "113816    1,2,7,20,64,200,686,2324,8194,29084,104860,381...\n",
       "113817    3,5,7,11,13,17,19,29,31,41,43,47,53,59,61,67,7...\n",
       "113818    0,8,26,57,104,170,258,371,512,684,890,1133,141...\n",
       "113819    1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,1,0,0,0,...\n",
       "113820    0,1,3,0,4,6,10,12,16,22,24,0,4,6,10,16,22,24,3...\n",
       "113821    1,0,1,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,-2,0,0,0,...\n",
       "113822    1,7,13,21,25,31,37,41,49,55,61,69,73,81,87,93,...\n",
       "113823    1,9,17,9,15,17,9,13,9,15,17,9,11,17,9,13,9,15,...\n",
       "113824    13,25589,47051,67589,136889,313589,960389,1005...\n",
       "113825    2,6,10,26,42,58,68,196,266,602,1170,1288,1290,...\n",
       "113826    37182145,46881835,50115065,59814755,1078282205...\n",
       "113827    1,2,3,4,6,7,8,9,11,12,16,17,21,22,23,24,25,27,...\n",
       "113828    1,106,11516,1243426,9688988696,96978050779606,...\n",
       "113829    96,20596,3171708,442135180,61706303456,8496020...\n",
       "113830    29,1001,32529,1044001,33407143,1068969245,3420...\n",
       "113831    1,2,4,3,6,9,5,7,12,17,8,10,14,22,25,13,11,15,2...\n",
       "113832    1,2,0,0,2,0,0,0,0,2,0,0,0,0,0,0,2,0,0,0,0,0,0,...\n",
       "113833    3,4,5,7,10,14,20,29,43,64,95,142,212,317,475,7...\n",
       "113834    1,1,4,9,31,40,671,711,2804,6319,21761,28080,47...\n",
       "113835    12,50,113,201,314,452,615,804,1017,1256,1520,1...\n",
       "113836    1,1,2,3,5,233,238,471,709,1180,54989,56169,111...\n",
       "113837    1,6,45,378,3402,32076,312741,3127410,31899582,...\n",
       "113838    7,7,3,2,3,9,5,4,4,7,3,5,1,6,2,6,8,6,1,5,1,0,7,...\n",
       "113839    1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,...\n",
       "113840    0,0,4,1198,1829388,23796035743,214296750607865...\n",
       "113841    0,-1,-1,-1,-1,10324303,-6586524273069171148,11...\n",
       "113842    0,1,9,85,801,7549,71145,670501,6319089,5955380...\n",
       "113843    2,3,3,4,6,4,5,10,10,5,6,15,20,15,6,7,21,35,35,...\n",
       "113844                      5,7,179,229,439,557,6113,223999\n",
       "Name: seq, Length: 113845, dtype: object"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['seq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
